{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835ddaf0",
   "metadata": {},
   "source": [
    "# Login to HuggingFace Hub\n",
    "\n",
    "Create a community account and create toekns:\n",
    "https://huggingface.co/settings/tokens\n",
    "\n",
    "With the account and token, you can access pretrain models, open source datasets and push your finetuned model to the hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2517426a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29813d5f706b49409fda03daa0bd8fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c520f3c",
   "metadata": {},
   "source": [
    "## Hugging Face Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65766546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset billsum (/Users/matthewong/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")\n",
    "billsum = billsum.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc966d1",
   "metadata": {},
   "source": [
    "# Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3571e6de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The people of the State of California do enact as follows:\\n\\n\\nSECTION 1.\\nArticle 3.3 (commencing with Section 20119) is added to Chapter 1 of Part 3 of Division 2 of the Public Contract Code, to read:\\nArticle  3.3. Los Angeles Unified School District — Best Value Procurement\\n20119.\\n(a) It is the intent of the Legislature to enable school districts to use cost-effective options for building and modernizing school facilities. The Legislature has recognized the merits of the best value procurement method process in the past by authorizing its use for projects undertaken by the University of California.\\n(b) The Legislature also finds and declares that school districts using the best value procurement method require a clear understanding of the roles and responsibilities of each participant in the best value process. As reflected in the University of California report to the Legislature, the benefits of a best value procurement method include a reduction in contract delays, change orders, and claims producing a savings in both contract costs and administration.\\n(c) It is the intent of the Legislature to provide an optional, alternative procedure for bidding and building school construction projects.\\n20119.1.\\nAs used in this article:\\n(a) “Apprenticeable occupation” means an occupation for which the Chief of the Division of Apprenticeship Standards had approved an apprenticeship program pursuant to Section 3075 of the Labor Code prior to January 1, 2015.\\n(b) “Best value” means a procurement process whereby the selected bidder may be selected on the basis of objective criteria for evaluating the qualifications of bidders with the resulting selection representing the best combination of price and qualifications.\\n(c) “Best value contract” means a competitively bid contract entered into pursuant to this article.\\n(d) “Best value contractor” means a properly licensed person, firm, or corporation that submits a bid for and is awarded a best value contract.\\n(e) “Best value score” means the resulting score when the school district divides the bidder’s price by the bidder’s qualification score.\\n(f) “Demonstrated management competency” means the experience, competency, capability, and capacity of the proposed management staffing to complete projects of similar size, scope, or complexity.\\n(g) “Financial condition” means the financial resources needed to perform the contract. The criteria used to evaluate a bidder’s financial condition shall include, at a minimum, capacity to obtain all required payment bonds and required insurance.\\n(h) “Governing board” or “governing board of the school district” means the governing board of the Los Angeles Unified School District.\\n(i) “Labor compliance” means the ability to comply with, and past conformance with, contract and statutory requirements for the payment of wages and qualifications of the workforce. The criteria used to evaluate a bidder’s labor compliance shall include, at a minimum, the bidder’s ability to comply with the apprenticeship requirements of the California Apprenticeship Council and the Department of Industrial Relations, its past conformance with such requirements, and its past conformance with requirements to pay prevailing wages on public works projects.\\n(j) “Project” has the same meaning as “public project” as defined in subdivision (c) of Section 22002.\\n(k) “Qualifications” means financial condition, relevant experience, demonstrated management competency, labor compliance, the safety record of the bidder, and, to the extent relevant, the preceding qualifications as they pertain to all subcontractors proposed to be used by the bidder for designated portions of the work.\\n(l) “Relevant experience” means the experience, competency, capability, and capacity to complete projects of similar size, scope, or complexity.\\n(m) “Safety record” shall be deemed “acceptable” if a contractor’s experience modification rate for the most recent three-year period is an average of 1.00 or less, and its average total recordable injury or illness rate and average lost work rate for the most recent three-year period do not exceed the applicable statistical standards for its business category or if the bidder is a party to an alternative dispute resolution system as provided for in Section 3201.5 of the Labor Code.\\n(n) “School district” means the Los Angeles Unified School District.\\n(o) “Skilled and trained workforce” means a workforce that meets all of the following conditions:\\n(1) All the workers are either skilled journeypersons or apprentices registered in an apprenticeship program approved by the Chief of the Division of Apprenticeship Standards.\\n(2) (A) As of January 1, 2016, at least 20 percent of the skilled journeypersons employed to perform work on the contract or project by the entity and each of its subcontractors at every tier are graduates of an apprenticeship program for the applicable occupation that was either approved by the Chief of the Division of Apprenticeship Standards pursuant to Section 3075 of the Labor Code or located outside California and approved for federal purposes pursuant to the apprenticeship regulations adopted by the United States Secretary of Labor.\\n(B) As of January 1, 2017, at least 30 percent of the skilled journeypersons employed to perform work on the contract or project by the entity and each of its subcontractors at every tier are graduates of an apprenticeship program for the applicable occupation that was either approved by the Chief of the Division of Apprenticeship Standards pursuant to Section 3075 of the Labor Code or located outside California and approved for federal purposes pursuant to the apprenticeship regulations adopted by the United States Secretary of Labor.\\n(C) As of January 1, 2018, at least 40 percent of the skilled journeypersons employed to perform work on the contract or project by the entity and each of its subcontractors at every tier are graduates of an apprenticeship program for the applicable occupation that was either approved by the Chief of the Division of Apprenticeship Standards pursuant to Section 3075 of the Labor Code or located outside California and approved for federal purposes pursuant to the apprenticeship regulations adopted by the United States Secretary of Labor.\\n(D) As of January 1, 2019, at least 50 percent of the skilled journeypersons employed to perform work on the contract or project by the entity and each of its subcontractors at every tier are graduates of an apprenticeship program for the applicable occupation that was either approved by the Chief of the Division of Apprenticeship Standards pursuant to Section 3075 of the Labor Code or located outside California and approved for federal purposes pursuant to the apprenticeship regulations adopted by the United States Secretary of Labor.\\n(E) As of January 1, 2020, at least 60 percent of the skilled journeypersons employed to perform work on the contract or project by the entity and each of its subcontractors at every tier are graduates of an apprenticeship program for the applicable occupation that was either approved by the Chief of the Division of Apprenticeship Standards pursuant to Section 3075 of the Labor Code or located outside California and approved for federal purposes pursuant to the apprenticeship regulations adopted by the United States Secretary of Labor.\\n(3) For an apprenticeable occupation in which no apprenticeship program had been approved by the chief prior to January 1, 1995, up to one-half of the graduation percentage requirements of paragraph (2) may be satisfied by skilled journeypersons who commenced working in the apprenticeable occupation prior to the chief’s approval of an apprenticeship program for that occupation in the county in which the project is located.\\n(p) “Skilled journeyperson” means a worker who either:\\n(1) Graduated from an apprenticeship program for the applicable occupation that was approved by the chief or located outside California and approved for federal purposes pursuant to the apprenticeship regulations adopted by the federal Secretary of Labor.\\n(2) Has at least as many hours of on-the-job experience in the applicable occupation as would be required to graduate from an apprenticeship program for the applicable occupation that is approved by the chief.\\n20119.2.\\n(a) This article provides for a pilot program for the Los Angeles Unified School District to use best value procurement for projects over one million dollars ($1,000,000).\\n(b) The governing board, for projects over one million dollars ($1,000,000), before December 31, 2020, may use the best value procurement method in accordance with this article.\\n(c) The bidder may be selected on the basis of the best value to the governing board of the school district. In order to implement this method of selection, the governing board of the school district shall adopt and publish procedures and required guidelines for evaluating the qualifications of the bidders that ensure the best value selections by the school district are conducted in a fair and impartial manner. These procedures and guidelines shall conform to this article and shall be mandatory for the school district when using best value selection.\\n(d) If the governing board of the school district deems it to be for the best interest of the school district, the governing board of the school district, on the refusal or failure of the selected bidder for a project to execute a tendered contract, may award it to the bidder with the second lowest best value score. If the second bidder fails or refuses to execute the contract, the governing board of the school district may likewise award it to the bidder with the third lowest best value score.\\n(e) The governing board of the school district shall let any contract for a project pursuant to this article to the selected bidder that represents the best value or else reject all bids.\\n(f) (1) If the school district elects to award a project pursuant to this section, retention proceeds withheld by the district from the selected best value contractor shall not exceed 5 percent if a performance and payment bond, issued by an admitted surety insurer, is required in the solicitation of bids.\\n(2) In a contract between the selected best value contractor and a subcontractor, and in a contract between a subcontractor and any subcontractor thereunder, the percentage of the retention proceeds withheld shall not exceed the percentage specified in the contract between the district and the selected best value contractor. If the selected best value contractor provides written notice to a subcontractor that, prior to or at the time the bid is requested, a bond may be required and the subcontractor subsequently is unable or refuses to furnish a bond to the selected best value contractor, then the selected best value contractor may withhold retention proceeds in excess of the percentage specified in the contract between the district and the selected best value contractor from any payment made by the selected best value contractor to the subcontractor.\\n(g) All subcontractors bidding on contracts pursuant to this chapter shall be afforded the protection contained in Chapter 4 (commencing with Section 4100) of Part 1.\\n20119.3.\\nThe governing board of the school district shall proceed in accordance with the following when awarding best value contracts under this article:\\n(a) The school district shall prepare a solicitation for bids and give notice pursuant to Section 20112.\\n(b) (1) The school district shall establish a procedure to prequalify bidders as required by this code. Information submitted by the bidder as part of the evaluation process shall not be open to public inspection to the extent that information is exempt from disclosure under the California Public Records Act (Chapter 3.5 (commencing with Section 6250) of Division 7 of Title 1 of the Government Code).\\n(2) A best value entity shall not be prequalified or shortlisted unless the entity provides an enforceable commitment to the governing board that the entity and its subcontractors at every tier will use a skilled and trained workforce to perform all work on the project or contract that falls within an apprenticeable occupation in the building and construction trades.\\n(3) An entity’s commitment that a skilled and trained workforce will be used to perform the project or contract may be established by any of the following:\\n(A) The entity’s agreement with the school district that the entity and its subcontractors at every tier will comply with the requirements of this subdivision and that the entity will provide the governing board of the school district with evidence, on a monthly basis while the project or contract is being performed, that the entity and its subcontractors are complying with the requirements of this subdivision.\\n(B) If the governing board has entered into a project labor agreement that will bind all contractors and subcontractors performing work on the project or contract and that includes the requirements of this subdivision, the entity’s agreement that it will become a party to that project labor agreement.\\n(C) Evidence that the entity has entered into a project labor agreement that includes the requirements of this subdivision and that will bind the entity and all its subcontractors at every tier performing the project or contract.\\n(c) Each solicitation for bids shall do all of the following:\\n(1) Invite prequalified bidders to submit sealed bids in the manner prescribed by this article.\\n(2) Include a section identifying and describing the following:\\n(A) Criteria that the school district will consider in evaluating the qualifications of the bidders.\\n(B) The methodology and rating or weighting system that will be used by the school district in evaluating bids.\\n(C) The relative importance or weight assigned to the criteria for evaluating the qualifications of bidders identified in the request for bids.\\n(d) Final evaluation of the bidders shall be done in a manner that prevents the identity of the bidders and the cost or price information from being revealed in evaluating the qualifications of the bidders prior to completion of qualification scoring.\\n20119.4.\\nSelection of the best value contractor shall be made as follows:\\n(a) (1) The school district shall evaluate the qualifications of the bidders based solely upon the criteria set forth in the solicitation documents, and shall assign a qualification score to each bid.\\n(2) Qualification scores shall be determined by using only the criteria and selection procedures specifically identified in the request for proposals. The following minimum factors, however, shall be weighted as deemed appropriate by the school district:\\n(A) Relevant experience.\\n(B) Safety record.\\n(C) Other factors identified in the request for proposal.\\n(b) To determine the best value contractor, the school district shall divide each bidder’s price by its qualifications score. A preference of up to 5 percent shall be applied to the price of a bid submitted by a small business, as defined by the school district, before dividing the bidder’s price by its qualification score. The lowest resulting cost per quality point will represent the best value bid. The award of the contract shall be made to the bidder whose bid is determined, by the school district in writing, to be the best value to the school district.\\n(c) The school district shall issue a written decision of its contract award or else reject all bids.\\n(d) Upon issuance of a contract award, the school district shall publicly announce its award identifying the project, the project price, the best value contractor to which the award is made, as well as the prices, qualification scores, and resulting costs per qualification point for all responsive bidders. The contract file shall include documentation sufficient to support the decision to award.\\n20119.5.\\n(a) (1) A school district that uses the best value procurement method pursuant to this article shall submit to the appropriate policy and fiscal committees of the Legislature an interim and final report on the use of the best value procurement method. The reports shall be prepared by an independent third party and the school district shall pay for the cost of the report. The reports shall be submitted to the appropriate policy and fiscal committees of the Legislature as follows:\\n(A) An interim report on or before July 1, 2018.\\n(B) A final report on or before January 1, 2020.\\n(2) A report shall include, but is not limited to, the following information:\\n(A) A description of the projects awarded using the best value procedures.\\n(B) The contract award amounts.\\n(C) The best value contractors awarded the projects.\\n(D) A description of any written protests concerning any aspect of the solicitation, bid, or award of the best value contracts, including the resolution of the protests.\\n(E) A description of the prequalification process.\\n(F) The criteria used to evaluate the bids, including the weighting of the criteria and an assessment of the effectiveness of the methodology.\\n(G) If a project awarded under this article has been completed, an assessment of the project performance, to include a summary of any delays or cost increases.\\n(b) The requirement for submitting a report imposed pursuant to subdivision (a) is inoperative on January 1, 2021, pursuant to Section 10231.5 of the Government Code.\\n20119.6.\\nExcept as otherwise provided in this article, the best value procurement method is not intended to change any guideline, criterion, procedure, or requirement of the governing board of the school district to let a contract for a project to the lowest responsible bidder or else reject all bids.\\n20119.7.\\nThis article shall remain in effect only until January 1, 2021, and as of that date is repealed, unless a later enacted statute, that is enacted before January 1, 2021, deletes or extends that date.\\nSEC. 2.\\nThe Legislature finds and declares that a special law is necessary and that a general law cannot be made applicable within the meaning of Section 16 of Article IV of the California Constitution because of the need to establish a pilot project for the Los Angeles Unified School District to determine the potential benefits and consequences of using best value procurement to facilitate infrastructure improvements and ease fiscal impacts.',\n",
       " 'summary': 'The Local Agency Public Construction Act requires the governing board of any school district to let any contract for a public project, as defined, involving an expenditure of $15,000 or more, to the lowest responsible bidder that gives security as the board requires, or else reject all bids.\\nThis bill would establish a pilot program to authorize the Los Angeles Unified School District to use, before December 31, 2020, a best value procurement method for bid evaluation and selection for public projects that exceed $1,000,000. The bill would establish various requirements applicable to the use of the best value procurement method under this authorization. The bill would require the school district to submit an interim and final report to the appropriate policy and fiscal committees of the Legislature on the use of the best value procurement method pursuant to the bill, in accordance with a specified schedule. These provisions would be repealed on January 1, 2021.\\nThis bill would make legislative findings and declarations as to the necessity of a special statute for the Los Angeles Unified School District.',\n",
       " 'title': 'An act to add and repeal Article 3.3 (commencing with Section 20119) of Chapter 1 of Part 3 of Division 2 of the Public Contract Code, relating to best value procurement.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7495b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'summary', 'title'],\n",
       "        num_rows: 989\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'summary', 'title'],\n",
       "        num_rows: 248\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b440e1",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "417f8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f96f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3690cc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "396fafe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4424155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8df541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f8ab34",
   "metadata": {},
   "source": [
    "# Finetune Model with CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d7067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "cpu_model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7dbcc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewong/opt/anaconda3/envs/langmodel/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [248/248 49:06, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.816046</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.605204</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.107600</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.544509</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.108200</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.528401</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=248, training_loss=3.0199228102161038, metrics={'train_runtime': 2957.6008, 'train_samples_per_second': 1.338, 'train_steps_per_second': 0.084, 'total_flos': 1070824333246464.0, 'train_loss': 3.0199228102161038, 'epoch': 4.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_awesome_billsum_model_cpu\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    no_cuda=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=cpu_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134d11b",
   "metadata": {},
   "source": [
    "# Finetune Model with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82ce2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "gpu_model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9965ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [248/248 29:53, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.794135</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.587568</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.106200</td>\n",
       "      <td>0.106200</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.529297</td>\n",
       "      <td>0.135300</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.512336</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewong/opt/anaconda3/envs/langmodel/lib/python3.8/site-packages/transformers/generation/utils.py:2419: UserWarning: MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_1aidzjezue/croot/pytorch_1687856425340/work/aten/src/ATen/native/mps/operations/ReduceOps.mm:1271.)\n",
      "  if unfinished_sequences.max() == 0:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=248, training_loss=2.9696047382970012, metrics={'train_runtime': 1799.0295, 'train_samples_per_second': 2.199, 'train_steps_per_second': 0.138, 'total_flos': 1070824333246464.0, 'train_loss': 2.9696047382970012, 'epoch': 4.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_awesome_billsum_model_gpu\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=gpu_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ac0bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e101eb64a0d64bc096896f5e6bfbfe8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c68206f81e43d285c82d280e6d47c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin:   0%|          | 1.00/4.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/mattbeen/my_awesome_billsum_model\n",
      "   8dd7653..21c9633  main -> main\n",
      "\n",
      "WARNING:huggingface_hub.repository:To https://huggingface.co/mattbeen/my_awesome_billsum_model\n",
      "   8dd7653..21c9633  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/mattbeen/my_awesome_billsum_model\n",
      "   21c9633..e1b46d0  main -> main\n",
      "\n",
      "WARNING:huggingface_hub.repository:To https://huggingface.co/mattbeen/my_awesome_billsum_model\n",
      "   21c9633..e1b46d0  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/mattbeen/my_awesome_billsum_model/commit/21c96338ae094a6159b6394c36c27773b9e4618b'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push to huggingface hub\n",
    "#trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54be8ac1",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc243095",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"summarize: The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. And no one making under $400,000 per year will pay a penny more in taxes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d459f0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 103. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"the Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country.\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "my_hub_model = \"mattbeen/my_awesome_billsum_model\"\n",
    "summarizer = pipeline(\"summarization\", model=my_hub_model)\n",
    "summarizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114794e",
   "metadata": {},
   "source": [
    "--------------------------------Break-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1ac1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
